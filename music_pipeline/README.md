### Classification

In the project,  worked with the `churn_df` dataset to build a simple classification model using k-Nearest Neighbors (KNN).  specifically focused on the "account_length" and "customer_service_calls" as our features to predict the target variable "churn". Our goal was to convert these features and the target variable into NumPy arrays, which is a typical requirement for machine learning libraries like Scikit-Learn. Once our data was appropriately preprocessed,  created an instance of the KNN classifier and trained it on our data. So, in essence,  leveraged the KNN algorithm to analyze the relationship between account length and customer service calls, and how these factors might have influenced customer churn.

After fitting our k-Nearest Neighbors (KNN) classifier,  utilized it to predict the label of new data points. For training,  employed all the available data. Fortunately, there were new observations available, preloaded for us as X_new.  had the model knn, which  created and fit the data in a previous exercise, preloaded.  used our classifier to predict the labels of a new set of data points, X_new, represented as a numpy array. The X_new array included three new data points with values for "account_length" and "customer_service_calls". Through this exercise,  demonstrated the practical application of our trained KNN model in predicting churn based on new, unseen data.

 were provided with NumPy arrays containing the features as `X` and the target variable as `y`.  divided these into training and test sets, fitted a KNN classifier to the training data, and then computed its accuracy on the test data using the `.score()` method. This exercise gave us a practical experience in applying the train/test split methodology and enabled us to evaluate our KNN model's performance by measuring its accuracy on unseen test data.

Our objective was to build a model that could comprehend the relationship between features and the target variable, while also being able to generalize well when introduced to new observations. To achieve this,  generated accuracy scores for both the training and test sets using a KNN classifier.  varied the `n_neighbors` parameter, the results of which  plotted in a subsequent exercise. For this task,  worked with the training and test sets created from the `churn_df` dataset, preloaded as `X_train`, `X_test`, `y_train`, and `y_test`.  utilized the `KNeighborsClassifier` alongside `numpy` as `np`. Through this process,  gained a hands-on understanding of the concepts of overfitting and underfitting, as well as the importance of choosing the right level of complexity in a machine learning model.

After calculating the accuracy of the KNN model on the training and test sets using various values of `n_neighbors`, created a model complexity curve. This curve allowed us to visualize how the performance of our model changed as adjusted its complexity. To achieve this, utilized the variables `neighbors`, `train_accuracies`, and `test_accuracies`, all of which generated in a prior exercise. plotted these results to assist in finding the optimal number of neighbors for our model. By observing this curve, could see the trade-off between bias and variance as adjusted the `n_neighbors` parameter, which ultimately helped us fine-tune our model for better performance.

![download](https://github.com/ai-akuma/MachineLearning/assets/7444521/8d420723-3a6e-4f5f-8b2e-8ff1c93e4985)

### Regression

Worked with a dataset called `sales_df`, which contained information about advertising campaign expenditure across different media types and the corresponding number of dollars generated in sales for each campaign. The dataset included columns like `tv`, `radio`, `social_media`, and `sales`. The focus was primarily on the "radio" column, using its advertising expenditure as features to predict sales values.  started by creating the feature and target arrays and reshaping them to the format that scikit-learn requires. This process marked our initial steps in feature engineering and preparing data for predictive modeling.

After creating the feature and target arrays, I trained a linear regression model on all feature and target values. Given that the goal was to assess the relationship between the feature and target values, there was no need to split the data into training and test sets. I used the `sales` column as the target variable `y` and the `radio` column as the feature variable `X`, which was reshaped into a 2D array to fit the requirements of scikit-learn. The linear regression model provided a statistical analysis of the relationship between advertising expenditure on radio and the sales generated from it.

Once I built and trained the linear regression model using all available observations, I visualized its performance to interpret the relationship between radio advertising expenditure and sales values. For this visualization, I used `X`, an array of radio values, `y`, an array of sales values, and `predictions`, an array of the model's predicted values for `y` given `X`. The visualization helped in understanding how closely the predictions align with the actual sales values, indicating the effectiveness of radio advertising in influencing sales.

![download](https://github.com/ai-akuma/MachineLearning/assets/7444521/32c73faa-1e66-459e-aa87-376c61d7db1d)

Following the cross-validation process, I analyzed the results. I computed the mean, standard deviation, and the 95% confidence interval for the cross-validation results, represented by `cv_results`. These statistical metrics provided an understanding of the model's average performance, variability of performance, and the range where we can expect the true performance metric to lie with 95% confidence. All these computations utilized the `numpy` library, which is known for its capabilities to perform mathematical and logical operations on arrays efficiently.

Used Ridge regression, a regularized regression method that introduces a penalty term (alpha) multiplied by the squared values of the model parameters to the loss function. This helps to control the complexity of the model, reducing overfitting by constraining the size of the coefficients. Using all the features in the sales_df dataset to predict "sales", I fit several Ridge regression models with different alpha values. The data was split into X_train, X_test, y_train, and y_test to evaluate the performance of the model. I looped through a list of different alpha values, fitting a Ridge model for each one, and recorded their corresponding scores. This allowed me to assess the impact of different alpha values on the model's performance.

Applied Lasso regression to the sales_df dataset to uncover feature importance. Lasso regression, another form of regularized linear regression, introduces a penalty equal to the absolute value of the magnitude of coefficients. This can result in some coefficients being shrunk to zero, which essentially excludes insignificant features from the model. After fitting the Lasso model to the feature and target variable arrays, X and y, I plotted the model's coefficients. This allowed me to visually inspect the influence of each feature in predicting the target variable, as represented by the size of its corresponding coefficient. Feature names for the dataset, stored in sales_columns, were used for the plot's x-axis for easy reference.

![download](https://github.com/ai-akuma/MachineLearning/assets/7444521/5d302cfb-894f-4b8c-92d2-303760901b23)

### Fine Tuning

Worked with the `diabetes_df` dataset, aiming to predict whether individuals are likely to develop diabetes based on features such as Body Mass Index (BMI) and age. This binary classification problem categorized individuals into either having diabetes (1) or not (0). After loading the pandas DataFrame `diabetes_df` and splitting it into `X_train`, `X_test`, `y_train`, and `y_test`, I used a `KNeighborsClassifier()` for the prediction task. Upon fitting the model and making predictions on the test set, I produced a confusion matrix and a classification report to evaluate the performance of the classifier.

Constructed a logistic regression model utilizing all the features available in the `diabetes_df` dataset. The goal of the model was to predict the probability of individuals in the test set being diagnosed with diabetes. The `diabetes_df` dataset was appropriately split into training and test sets, namely `X_train`, `X_test`, `y_train`, and `y_test`, to ensure model validation and accuracy.

![download](https://github.com/ai-akuma/MachineLearning/assets/7444521/98b44765-9c71-4af9-b7ab-7da12c40af3a)

After creating a logistic regression model for predicting diabetes status, I plotted the Receiver Operating Characteristic (ROC) curve. The ROC curve is a powerful visualization tool that showcases how the true positive rate and false positive rate change with the decision threshold. Using the test labels (y_test) and the predicted probabilities for the test features to belong to the positive class (y_pred_probs), I was able to generate a ROC curve. This visualization helped interpret the model's performance across different thresholds, aiding in understanding the trade-off between sensitivity and specificity.

In order to enhance the logistic regression model's performance, I employed RandomizedSearchCV, a useful tool for hyperparameter tuning when the hyperparameter space is vast. Unlike GridSearchCV, RandomizedSearchCV only tests a fixed number of hyperparameter settings sampled from specified probability distributions, making it a more computationally efficient option. Using the pre-loaded training and test sets (`X_train`, `X_test`, `y_train`, and `y_test`) from the `diabetes_df` dataset, where the target was "diabetes", I defined a range of hyperparameters for the logistic regression model (`logreg`). Applying RandomizedSearchCV allowed me to identify the optimal hyperparameters among the defined options, thereby refining the model's performance in predicting diabetes status.


