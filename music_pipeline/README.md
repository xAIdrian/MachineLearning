### Classification

In the project, we worked with the `churn_df` dataset to build a simple classification model using k-Nearest Neighbors (KNN). We specifically focused on the "account_length" and "customer_service_calls" as our features to predict the target variable "churn". Our goal was to convert these features and the target variable into NumPy arrays, which is a typical requirement for machine learning libraries like Scikit-Learn. Once our data was appropriately preprocessed, we created an instance of the KNN classifier and trained it on our data. So, in essence, we leveraged the KNN algorithm to analyze the relationship between account length and customer service calls, and how these factors might have influenced customer churn.

After fitting our k-Nearest Neighbors (KNN) classifier, we utilized it to predict the label of new data points. For training, we employed all the available data. Fortunately, there were new observations available, preloaded for us as X_new. We had the model knn, which we created and fit the data in a previous exercise, preloaded. We used our classifier to predict the labels of a new set of data points, X_new, represented as a numpy array. The X_new array included three new data points with values for "account_length" and "customer_service_calls". Through this exercise, we demonstrated the practical application of our trained KNN model in predicting churn based on new, unseen data.

We were provided with NumPy arrays containing the features as `X` and the target variable as `y`. We divided these into training and test sets, fitted a KNN classifier to the training data, and then computed its accuracy on the test data using the `.score()` method. This exercise gave us a practical experience in applying the train/test split methodology and enabled us to evaluate our KNN model's performance by measuring its accuracy on unseen test data.

Our objective was to build a model that could comprehend the relationship between features and the target variable, while also being able to generalize well when introduced to new observations. To achieve this, we generated accuracy scores for both the training and test sets using a KNN classifier. We varied the `n_neighbors` parameter, the results of which we plotted in a subsequent exercise. For this task, we worked with the training and test sets created from the `churn_df` dataset, preloaded as `X_train`, `X_test`, `y_train`, and `y_test`. We utilized the `KNeighborsClassifier` alongside `numpy` as `np`. Through this process, we gained a hands-on understanding of the concepts of overfitting and underfitting, as well as the importance of choosing the right level of complexity in a machine learning model.

After calculating the accuracy of the KNN model on the training and test sets using various values of `n_neighbors`, we created a model complexity curve. This curve allowed us to visualize how the performance of our model changed as we adjusted its complexity. To achieve this, we utilized the variables `neighbors`, `train_accuracies`, and `test_accuracies`, all of which we generated in a prior exercise. We plotted these results to assist in finding the optimal number of neighbors for our model. By observing this curve, we could see the trade-off between bias and variance as we adjusted the `n_neighbors` parameter, which ultimately helped us fine-tune our model for better performance.

![download](https://github.com/ai-akuma/MachineLearning/assets/7444521/8d420723-3a6e-4f5f-8b2e-8ff1c93e4985)

